"""
Agent Loop Module
å®ç°å®Œæ•´çš„ Agent æ‰§è¡Œå¾ªç¯ï¼ŒåŒ…æ‹¬ LLM è°ƒç”¨ã€å·¥å…·æ‰§è¡Œã€ç»“æœå›ä¼ 
"""

import json
import asyncio
from typing import Optional, Dict, List, Any
from loguru import logger

from .memory import ConversationMemory
from .connection import ConnectionManager
from config import AgentConfig


class AgentError(Exception):
    """Agent å¼‚å¸¸"""
    pass


class ToolExecutionError(Exception):
    """å·¥å…·æ‰§è¡Œå¼‚å¸¸"""
    pass


class Agent:
    """
    Agent æ ¸å¿ƒæ‰§è¡Œå™¨
    å®ç°å®Œæ•´çš„ Agent Loopï¼š
    æ€è€ƒ â†’ å·¥å…·è°ƒç”¨ â†’ æ‰§è¡Œ â†’ ç»“æœå›ä¼  â†’ æœ€ç»ˆå›å¤
    """

    def __init__(self, config: AgentConfig):
        self.config = config
        self.connection_manager: Optional[ConnectionManager] = None
        self.tools_definitions: List[Dict[str, Any]] = []
        self.iteration: int = 0
        self._running = False
        self._memory: Optional[ConversationMemory] = None
        self._callbacks: Dict[str, List] = {}

    def register_callback(self, event: str, callback):
        """æ³¨å†Œå›è°ƒå‡½æ•°"""
        if event in self._callbacks:
            self._callbacks[event].append(callback)
        else:
            raise ValueError(f"Unknown event: {event}")

    def _trigger_callback(self, event: str):
        """è§¦å‘å›è°ƒ"""
        if event in self._callbacks:
            for callback in self._callbacks[event]:
                try:
                    callback()
                except Exception as e:
                    pass

    async def initialize(self, connection_manager: ConnectionManager):
        """åˆå§‹åŒ– Agent å’Œè¿æ¥"""
        self.connection_manager = connection_manager
        self._memory = ConversationMemory(config=self.config)
        self._running = True
        self.iteration = 0
        self._callbacks = {}

        # TODO: åŠ è½½å·¥å…·å®šä¹‰ï¼ˆéœ€è¦å…ˆå®ç° tools/registry.pyï¼‰
        # from tools import ToolRegistry
        # from tools import builtin
        # ToolRegistry.initialize(connection_manager)

        # æ³¨å†Œæ‰€æœ‰å·¥å…·
        from tools.builtin import register_builtin_tools
        from tools import ToolRegistry

        ToolRegistry.initialize(connection_manager)
        register_builtin_tools(self)

        # è·å–å·¥å…·å®šä¹‰
        self.tools_def = ToolRegistry.get_all_definitions()

        # æ˜¾ç¤ºå¯ç”¨æœºå™¨
        machines = self.connection_manager.list_machines()
        tools = ToolRegistry.get_all_names()
        # TODO: ä½¿ç”¨ Rich console UIï¼ˆå¯é€‰ï¼‰

        logger.info(f"ğŸ¤– Agent initialized. Machines: {machines}, Tools: {tools}")
        logger.info(f"ğŸ“‹ Loaded {len(self.tools_def)} tool definitions")

    async def run(self, user_input: str, callback=None) -> str:
        """è¿è¡Œ Agent ä¸»å¾ªç¯"""
        if not self.connection_manager:
            logger.error("âŒ Agent not initialized")
            return "âŒ Agent not initialized"

        self._running = True
        self.iteration = 0

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°è®°å¿†
        await self._add_user_message(user_input)
        self._trigger_callback("on_thought", iteration=1)

        final_response = ""

        while self._running and self.iteration < self.config.max_iterations:
            self.iteration += 1

            # Token æ£€æŸ¥
            from .config import AgentConfig
            current_tokens = self._memory.get_token_count()
            max_tokens = self.config.max_context_tokens

            if not await self._memory.is_within_limit():
                logger.warning(f"âš ï¸ Token ä¸Šé™è­¦å‘Š ({current_tokens} > {max_tokens})")
                await self._memory.truncate_oldest(keep_last_n=5)

            logger.info(f"--- Agent Iteration {self.iteration}/{self.config.max_iterations} (Tokens: {current_tokens}) ---")
            self._trigger_callback("on_thought", iteration=self.iteration)

            # Step 1: LLM æ€è€ƒ
            llm_response = await self._call_llm()
            self._add_assistant_message(llm_response["content"], llm_response.get("tool_calls"))

            # Step 2: æ£€æŸ¥å·¥å…·è°ƒç”¨
            tool_calls = self._extract_tool_calls(llm_response)

            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆå›å¤
            if not tool_calls:
                final_response = llm_response["content"]
                self._trigger_callback("on_final_response", response=final_response)
                break

            # Step 3: æ‰§è¡Œå·¥å…·
            self._trigger_callback("on_tool_execute", count=len(tool_calls))

            for tool_id, tool_call in tool_calls.items():
                await self._execute_single_tool(tool_id, tool_call, callback=callback)
                result = await self._execute_single_tool(tool_id, tool_call)
                self._add_tool_result(tool_id, result)
                self._trigger_callback("on_tool_result", tool=tool_call, result=result)

            # Step 4: ç»§ç»­ Loop
            await asyncio.sleep(0.1)

            # æ£€æŸ¥æœ€å¤§å¾ªç¯æ¬¡æ•°
            if self.iteration >= self.config.max_iterations:
                final_response = "âš ï¸ è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚"
                self._trigger_callback("on_error", error="Max iterations reached")
                break

        if self._running:
            self._running = False

        # è¾“å‡ºæœ€ç»ˆå›å¤
        if final_response:
            self._add_final_response(final_response)
            self._trigger_callback("on_final_response", response=final_response)

        logger.info(f"âœ… Agent æœ€ç»ˆå›å¤: {final_response[:100]}...")
        return final_response

    async def _call_llm(self) -> Dict[str, Any]:
        """è°ƒç”¨ LLM API"""
        try:
            responses = []
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    self.config.base_url,
                    headers={
                        "Authorization": f"Bearer {self.config.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.config.llm_model,
                        "messages": await self._memory.get_history(),
                        "temperature": 0.7,
                        "max_tokens": 2048,
                        "stream": False
                    }
                ) as resp:
                    return await resp.json()

        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            raise AgentError(f"LLM call failed: {str(e)}")

    def _extract_tool_calls(self, llm_response: Dict) -> Dict[str, dict]:
        """ä» LLM å“åº”ä¸­æå–å·¥å…·è°ƒç”¨"""
        try:
            import json

            tc = llm_response.get("tool_calls", [])
            validated_calls = []

            for tc in tc:
                if not all(k in tc for k in ["id", "name", "arguments"]):
                    continue

                # è§£æå‚æ•°
                try:
                    if isinstance(tc["arguments"], str):
                        tc["arguments"] = json.loads(tc["arguments"])
                    else:
                        tc["arguments"] = {}

                validated_calls.append(tc)

            return {tc["id"]: tc for tc in validated_calls}

        except Exception as e:
            logger.warning(f"Tool call extraction failed: {e}")
            return {}

    async def _execute_single_tool(self, tool_id: str, tool_call: dict, callback=None) -> dict:
        """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨"""
        try:
            name = tool_call["name"]
            args = tool_call.get("arguments", {})

            # è·å–å·¥å…·å®ä¾‹ï¼ˆTODO: éœ€è¦å®Œæ•´çš„ ToolRegistryï¼‰
            # from tools import ToolRegistry
            # tool = ToolRegistry.get(name)
            # result = await tool.execute(**args)

            # ç®€åŒ–ç‰ˆï¼šç¡¬ç¼–ç å‡ ä¸ªå¸¸ç”¨å·¥å…·
            if name == "read_file":
                from .core.connection import ConnectionManager
                conn: ConnectionManager = self.connection_manager

                executor = conn.get_executor(args.get("target", "local"))

                # æ‰§è¡Œè¯»å–
                result = await executor.read_file(args.get("path"))

                response = {
                    "ok": result.ok,
                    "content": result.content if result.ok else None,
                    "path": result.path,
                    "target": args.get("target", "local"),
                    "error": result.error if not result.ok else None
                }

            elif name == "write_file":
                from .core.connection import ConnectionManager
                conn: conn = self.connection_manager

                executor = conn.get_executor(args.get("target", "local"))

                # æ‰§è¡Œå†™å…¥
                result = await executor.write_file(
                    args.get("path"),
                    args.get("content", "")
                )

                response = {
                    "ok": result.ok,
                    "path": result.path,
                    "target": args.get("target", "local"),
                    "error": result.error if not result.ok else None
                }

            elif name == "exec_shell":
                from .core.connection import ConnectionManager
                conn = conn = self.connection_manager

                executor = conn.get_executor(args.get("target", "local"))

                # æ‰§è¡Œå‘½ä»¤
                result = await executor.execute_command(
                    args.get("command", "")
                )

                response = {
                    "ok": result.ok,
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode,
                    "target": args.get("target", "local"),
                    "command": args.get("command", "")[:200],  # æˆªæ–­å‘½ä»¤
                    "error": result.error if not result.ok else None
                }

            else:
                response = {
                    "ok": False,
                    "error": f"Unknown tool: {name}"
                }

            return response

        except Exception as e:
            logger.error(f"Tool execution failed ({name}): {e}")
            return {
                "ok": False,
                "error": str(e)
            }

    def _add_user_message(self, message: str):
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        if self._memory:
            asyncio.create_task(self._memory.add_user_message(message))

    def _add_assistant_message(self, content: str, tool_calls=None):
        """æ·»åŠ  Assistant æ¶ˆæ¯"""
        if self._memory:
            asyncio.create_task(self._memory.add_assistant_message(content, tool_calls=tool_calls))

    def _add_tool_result(self, tool_id: str, result: dict):
        """æ·»åŠ å·¥å…·æ‰§è¡Œç»“æœ"""
        if self._memory:
            asyncio.create_task(self._memory.add_tool_result(tool_id, result))

    def _add_final_response(self, content: str):
        """æ·»åŠ æœ€ç»ˆå›å¤"""
        if self._memory:
            asyncio.create_task(self._memory.add_final_response(content))

    def _add_thought(self, iteration: int, **kwargs):
        """è®°å½•æ€è€ƒè¿‡ç¨‹"""
        if self._callbacks:
            for callback in self._callbacks.get("on_thought", []):
                try:
                    callback(iteration=iteration, **kwargs)
                except:
                    pass

    def _add_tool_execute(self, count: int, **kwargs):
        """è®°å½•å·¥å…·æ‰§è¡Œ"""
        if self._callbacks:
            for callback in self._callbacks.get("on_tool_execute", []):
                try:
                    callback(count=count, **kwargs)
                except:
                    pass

    def _add_tool_result(self, tool_id: str, result: dict, **kwargs):
        """è®°å½•å·¥å…·ç»“æœ"""
        if self._callbacks:
            for callback in self._callbacks.get("on_tool_result", []):
                try:
                    callback(tool_id=tool_id, result=result, **kwargs)
                except:
                    pass

    def _add_final_response(self, content: str, **kwargs):
        """è®°å½•æœ€ç»ˆå›å¤"""
        if self._callbacks:
            for callback in self._callbacks.get("on_final_response", []):
                try:
                    response=content, **kwargs)
                except:
                    pass

    def _add_error(self, error: str, **kwargs):
        """è®°å½•é”™è¯¯"""
        if self._callbacks:
            for callback in self._callbacks.get("on_error", []):
                try:
                    error=error, **kwargs)
                except:
                    pass

    def get_stats(self) -> dict:
        """è·å– Agent ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "iterations": self.iteration,
            "is_running": self._running,
            "machines": self.connection_manager.list_machines() if self.connection_manager else [],
            "tools": self.tools_def,
            "callbacksRegistered": list(self._callbacks.keys())
        } if self._memory else {}

    def shutdown(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        if self.connection_manager:
            await self.connection_manager.shutdown()

        logger.info("ğŸ”Œ Agent shutdown complete")
