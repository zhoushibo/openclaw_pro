"""
Agent æ ¸å¿ƒæ¨¡å—
å®Œæ•´çš„ Agent Loop å®ç°ï¼ŒåŒ…æ‹¬ LLM è°ƒç”¨ã€å·¥å…·æ‰§è¡Œã€ç»“æœå›ä¼ 
"""

import json
import asyncio
from typing import Optional, List, Dict, Any, Callable

from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel

import logging

from .memory import ConversationMemory
from .connection import ConnectionManager

from llm.client import LLMClient
from tools.registry import ToolRegistry
from tools.builtin import register_builtin_tools

from config import AgentConfig

logger = logging.getLogger(__name__)

console = Console()


class AgentError(Exception):
    """Agent å¼‚å¸¸"""
    pass


class Agent:
    """
    Agent æ ¸å¿ƒæ‰§è¡Œå™¨

    å®Œæ•´çš„ Agent Loopï¼š
    æ€è€ƒ â†’ å·¥å…·è°ƒç”¨ â†’ æ‰§è¡Œ â†’ ç»“æœå›ä¼  â†’ æœ€ç»ˆå›å¤
    """

    def __init__(self, config: AgentConfig):
        self.config = config
        self.llm: Optional[LLMClient] = None
        self.memory: Optional[ConversationMemory] = None
        self.connection_manager: Optional[ConnectionManager] = None
        self.tools_definitions: List[Dict[str, Any]] = []
        self.iteration = 0
        self._running = False
        self._callbacks: Dict[str, List[Callable]] = {
            "on_think": [],
            "on_tool_execute": [],
            "on_tool_result": [],
            "on_final_response": [],
            "on_error": []
        }

    def register_callback(self, event: str, callback: Callable) -> None:
        """æ³¨å†Œå›è°ƒå‡½æ•°"""
        if event in self._callbacks:
            self._callbacks[event].append(callback)
        else:
            raise ValueError(f"Unknown event: {event}")

    def _trigger_callback(self, event: str, *args, **kwargs) -> None:
        """è§¦å‘å›è°ƒ"""
        for callback in self._callbacks.get(event, []):
            try:
                if asyncio.iscoroutinefunction(callback):
                    asyncio.create_task(callback(*args, **kwargs))
                else:
                    callback(*args, **kwargs)
            except Exception as e:
                logger.error(f"Callback error for {event}: {e}")

    async def initialize(self) -> None:
        """åˆå§‹åŒ– Agent"""
        logger.info("ğŸš€ Initializing Agent...")

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.llm = LLMClient(self.config)

        # åˆå§‹åŒ–è®°å¿†
        self.memory = ConversationMemory(self.config)

        # åˆå§‹åŒ–è¿æ¥ç®¡ç†å™¨
        self.connection_manager = ConnectionManager(self.config)
        await self.connection_manager.initialize()

        # åˆå§‹åŒ–å·¥å…·æ³¨å†Œè¡¨ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        ToolRegistry.initialize(self.connection_manager)

        # æ³¨å†Œå†…ç½®å·¥å…·
        register_builtin_tools()

        # è·å–å·¥å…·å®šä¹‰
        self.tools_definitions = ToolRegistry.get_all_definitions()

        # æ˜¾ç¤ºçŠ¶æ€
        machines = self.connection_manager.list_machines()
        tools = ToolRegistry.get_all_names()

        console.print(Panel(
            f"[bold]ğŸŒ Machines:[/bold] {', '.join(machines)}\n"
            f"[bold]ğŸ”§ Tools:[/bold] {', '.join(tools)}",
            title="Agent Initialized",
            border_style="green"
        ))

        logger.info(f"âœ… Agent initialized. Machines: {machines}, Tools: {tools}")

    async def run(self, user_input: str) -> str:
        """è¿è¡Œ Agent ä¸»å¾ªç¯"""
        if not self.connection_manager:
            raise AgentError("Agent not initialized. Call initialize() first.")

        self._running = True
        self.iteration = 0
        final_response = ""

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.memory.add_user_message(user_input)

        console.print(f"\n[bold blue]ğŸ‘¤ User:[/bold blue] {user_input}\n")
        logger.info(f"ğŸ“¥ Received: {user_input[:100]}...")

        try:
            while self._running and self.iteration < self.config.max_iterations:
                self.iteration += 1

                # Token æ£€æŸ¥
                current_tokens = self.memory.get_token_count()

                if not self.memory.is_within_limit():
                    console.print(Panel(
                        f"âš ï¸ Token ä¸Šé™ ({current_tokens} > {self.config.max_context_tokens})",
                        style="yellow"
                    ))
                    self.memory.truncate_oldest(keep_last_n=5)

                logger.info(f"--- Iteration {self.iteration}/{self.config.max_iterations} ---")

                # Step 1: LLM æ€è€ƒ
                self._trigger_callback("on_think", iteration=self.iteration)
                console.print(f"[dim]ğŸ¤” Thinking... (Step {self.iteration})[/dim]")

                llm_response = await self._call_llm()

                # ä¿å­˜ Assistant æ¶ˆæ¯
                self.memory.add_assistant_message(
                    llm_response.get("content", ""),
                    llm_response.get("tool_calls")
                )

                # Step 2: æ£€æŸ¥å·¥å…·è°ƒç”¨
                tool_calls = self._extract_tool_calls(llm_response)

                if not tool_calls:
                    final_response = llm_response.get("content", "")
                    self._trigger_callback("on_final_response", response=final_response)
                    break

                # Step 3: æ‰§è¡Œå·¥å…·
                console.print(f"[yellow]âš¡ Executing {len(tool_calls)} tool(s)...[/yellow]")

                for tool_call in tool_calls:
                    self._trigger_callback("on_tool_execute", tool_call=tool_call)

                    tool_result = await self._execute_single_tool(tool_call)

                    self._trigger_callback("on_tool_result", tool_call=tool_call, result=tool_result)

                # Step 4: ç»“æœå›ä¼ 
                self.memory.add_tool_result(
                    tool_call.get("id", "unknown"),
                    json.dumps(tool_result, ensure_ascii=False)
                )

                await asyncio.sleep(0.1)

                if self.iteration >= self.config.max_iterations:
                    final_response = "âš ï¸ è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚"
                    logger.warning("âš ï¸ Reached max iterations")

        except Exception as e:
            logger.error(f"Agent run error: {e}")
            self._trigger_callback("on_error", error=e)
            final_response = f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
            raise

        finally:
            self._running = False

        console.print(f"\n[bold green]ğŸ¤– Agent:[/bold green]")
        console.print(Markdown(final_response))

        return final_response

    async def _call_llm(self) -> Dict[str, Any]:
        """è°ƒç”¨ LLM"""
        try:
            response = await self.llm.chat(
                messages=self.memory.get_history(),
                tools=self.tools_definitions if self.tools_definitions else None
            )
            return response
        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            raise AgentError(f"LLM call failed: {str(e)}")

    def _extract_tool_calls(self, llm_response: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä» LLM å“åº”ä¸­æå–å·¥å…·è°ƒç”¨"""
        tool_calls = llm_response.get("tool_calls", [])

        if not tool_calls:
            return []

        validated_calls = []

        for tc in tool_calls:
            if not all(k in tc for k in ["id", "name", "arguments"]):
                logger.warning(f"Invalid tool call format: {tc}")
                continue

            try:
                if isinstance(tc["arguments"], str):
                    tc["arguments"] = json.loads(tc["arguments"])
            except json.JSONDecodeError as e:
                logger.warning(f"Failed to parse tool arguments: {e}")
                tc["arguments"] = {}

            validated_calls.append(tc)

        return validated_calls

    async def _execute_single_tool(self, tool_call: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨"""
        name = tool_call.get("name")
        args = tool_call.get("arguments", {})
        call_id = tool_call.get("id", "unknown")

        if not name:
            return {"ok": False, "error": "Tool name is required"}

        try:
            logger.info(f"ğŸ”§ Executing tool: {name} with args: {args}")

            tool = ToolRegistry.get(name)
            result = await tool.execute(**args)

            target = args.get("target", "local")

            if result.get("ok"):
                console.print(f" âœ… [green]{name}[/green] on [cyan]{target}[/cyan]")
            else:
                console.print(
                    f" âŒ [red]{name}[/red] on [cyan]{target}[/cyan]: {result.get('error', 'Unknown error')}"
                )

            return result

        except Exception as e:
            logger.error(f"Tool execution failed: {name}: {e}")

            error_result = {
                "ok": False,
                "error": str(e)
            }

            console.print(f" âŒ [red]{name}[/red] failed: {e}")

            return error_result

    async def shutdown(self) -> None:
        """å…³é—­ Agent"""
        logger.info("ğŸ›‘ Shutting down Agent...")
        self._running = False

        if self.connection_manager:
            await self.connection_manager.shutdown()

        console.print("[dim]Agent shutdown complete.[/dim]")

    def get_stats(self) -> Dict[str, Any]:
        """è·å– Agent ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "iterations": self.iteration,
            "token_count": self.memory.get_token_count() if self.memory else 0,
            "message_count": len(self.memory.get_history()) if self.memory else 0,
            "machines": self.connection_manager.list_machines() if self.connection_manager else [],
            "tools": ToolRegistry.get_all_names()
        }
